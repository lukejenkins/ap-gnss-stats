# AI Rules for ap-gnss-stats

Every time you choose to apply a rule(s), explicitly state the rule(s) in the output. You can abbreviate the rule description to a single word or phrase.

This project is to assist network administrators with the GNSS (Global Navigation Satellite System) statistics generated by Cisco Wi-Fi Access Points.
- This project should start with a reusable python library that is for parsing the output from the cli command `show gnss info`.
  - There will be public example files in the repository to use for development and testing. These will have been anonymized to some degree.
  - There will be a private examples directory (that is included in the .gitignore file) for users to place additional logs to test against.
  - For this first phase, we will write a python program that reads one or more log files, and using the library we're writing, parses out all of the desired information.
    - The JSON data should include
      - The name and version of the CLI program creating the record.
      - The name and versions of the parsing library used for the output.
      - A timestamp of the current time.
      - The filename, file created timestamp, and file modified timestamp of the file that the record was parsed from.
    - This program should generate a JSON file that includes all of the parsed data for each AP.
    - The filename of the JSON file should include the hostname of the AP and a timestamp parsed from the log file.
    - There will be an option to create a log file that includes all of the debuging output per log file provided to the program.
- The second phase will be to write another program that uses netmiko to connect to an AP such as a Cisco CW9166i AP via SSH.
  - This program then will run the `show gnss info` CLI command in the EXEC shell to gather live data.
  - This program will then use the same library as in the first phase to parse the output from the command.
    - The JSON data should include
    - The name and version of the CLI program creating the record.
    - The name and versions of the parsing library used for the output.
    - A timestamp of the current time.
    - The hostname or IP of the AP being connected to.
  - There will be an option to create a full log of all SSH traffic for each session.
    - The filename of this log file should include the hostname of the AP and a timestamp.
  - This program should generate a JSON file that includes all of the parsed data for each AP.
- The third phase will be to write a program to push the parsed JSON from an SSH session to an instance of Prometheus.
- There may be additional phases added.
- For all libraries and programs, there will be options to turn on debugging to the CLI so that the user can see what the program is doing.


## CODING_PRACTICES

### Guidelines for SUPPORT_LEVEL

#### SUPPORT_BEGINNER

- When running in agent mode, execute up to 3 actions at a time and ask for approval or course correction afterwards.
- Write code with clear variable names and include explanatory comments for non-obvious logic. Avoid shorthand syntax and complex patterns.
- Provide full implementations rather than partial snippets. Include import statements, required dependencies, and initialization code.
- Add defensive coding patterns and clear error handling. Include validation for user inputs and explicit type checking.
- Suggest simpler solutions first, then offer more optimized versions with explanations of the trade-offs.
- Briefly explain why certain approaches are used and link to relevant documentation or learning resources.
- When suggesting fixes for errors, explain the root cause and how the solution addresses it to build understanding. Ask for confirmation before proceeding.
- Offer introducing basic test cases that demonstrate how the code works and common edge cases to consider.


### Guidelines for DOCUMENTATION

#### DOC_UPDATES

- Update relevant documentation in /docs when modifying features
- Keep README.md in sync with new capabilities
- Maintain changelog entries in CHANGELOG.md


### Guidelines for VERSION_CONTROL

#### GITHUB

- Use pull request templates to standardize information provided for code reviews
- Configure required status checks to prevent merging code that fails tests or linting
- Use GitHub Actions for CI/CD workflows to automate testing and deployment
- Implement CODEOWNERS files to automatically assign reviewers based on code paths
- Use GitHub Projects for tracking work items and connecting them to code changes


### Guidelines for ARCHITECTURE

#### ADR

- Create ADRs in /docs/adr/{name}.md for:
- 1) Major dependency changes
- 2) Architectural pattern changes
- 3) New integration patterns
- 4) Database schema changes


## TESTING

### Guidelines for UNIT

#### PYTEST

- Use fixtures for test setup and dependency injection
- Implement parameterized tests for testing multiple inputs for {{function_types}}
- Use monkeypatch for mocking dependencies



## Code Style and Structure

- Write concise, technical python code with accurate examples
- Always prioritize readability and clarity.
- Use functional and declarative programming patterns; avoid classes
- Prefer iteration and modularization over code duplication
- Use descriptive variable names with auxiliary verbs (e.g., isLoading, hasError)
- Use the `typing` module for type annotations (e.g., `List[str]`, `Dict[str, int]`).
- Break down complex functions into smaller, more manageable functions.
- Write code with good maintainability practices, including comments on why certain design decisions were made.
- Handle edge cases and write clear exception handling.
- For libraries or external dependencies, mention their usage and purpose in comments.
- Use consistent naming conventions and follow language-specific best practices.
- Write concise, efficient, and idiomatic code that is also easily understandable.

## Tech Stack

- Python 3.x
- netmiko
- dotenv

## Naming Conventions

- Use snake_case for variable and function names.
- Use CamelCase for class names.
- Follow PEP 8 style guidelines.

## Error Handling

- Implement proper error boundaries
- Log errors appropriately for debugging
- Provide user-friendly error messages
- Handle network failures gracefully

## Git Usage

Commit Message Prefixes:

- "fix:" for bug fixes
- "feat:" for new features
- "perf:" for performance improvements
- "docs:" for documentation changes
- "style:" for formatting changes
- "refactor:" for code refactoring
- "test:" for adding missing tests
- "chore:" for maintenance tasks

Rules:

- Use lowercase for commit messages
- Keep the summary line concise
- Include description for non-obvious changes
- Reference issue numbers when applicable

## Documentation

- Provide docstrings following PEP 257 conventions.

## Development Workflow

- Use proper version control
- Implement proper code review process
- Test in multiple environments
- Follow semantic versioning for releases
- Maintain changelog

# GITHUB_ACTIONS

## Workflow Overview

The repository uses GitHub Actions for continuous integration and deployment with the following workflows:

1. **Testing**: Runs on each pull request and push to main branch
2. **Linting**: Runs on each pull request and push to main branch
3. **Release**: Triggered when a new tag is created or manually from the Actions tab

## Branch Protection

Protected branches: main, develop

Always enforce the following rules on protected branches:
- Require pull request reviews before merging
- Require status checks to pass before merging
- Require branches to be up to date before merging

## Testing Workflow

```yaml
name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, '3.10']

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        pip install -e .
    - name: Test with pytest
      run: |
        pytest --cov=ap_gnss_stats tests/ --cov-report=xml
    - name: Upload coverage report
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

## Linting Workflow

```yaml
name: Lint

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort mypy
    - name: Lint with flake8
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
    - name: Check formatting with black
      run: |
        black --check .
    - name: Check imports with isort
      run: |
        isort --check-only --profile black .
    - name: Type check with mypy
      run: |
        mypy ap_gnss_stats/
```

## Release Workflow

```yaml
name: Release

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:

jobs:
  build-and-publish:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
    - name: Build package
      run: |
        python -m build
    - name: Publish to PyPI
      if: startsWith(github.ref, 'refs/tags/v')
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        user: __token__
        password: ${{ secrets.PYPI_API_TOKEN }}
```

## Git Commands

Always use terminal command: `git branch` to check your current branch before making changes.

For creating new feature branches:
```bash
git checkout -b feature/descriptive-name main
```

For creating bugfix branches:
```bash
git checkout -b bugfix/issue-number main
```

Follow conventional commits for all commit messages:
```
feat: add new feature
fix: correct bug
docs: update documentation
chore: update build tasks
test: add or update tests
```

# BRANCHING_STRATEGY

## Protected Branches

The following branches are protected and require pull request reviews before merging:

- `main`: Production-ready code that has been thoroughly tested
- `develop`: Integration branch for features being developed for the next release

## Protection Rules

All protected branches enforce these rules:

- Require at least one approving review before merging
- Require status checks to pass (tests, linting)
- Require branches to be up to date before merging
- No force pushes allowed
- No deletion of the branch

## Branch Naming Conventions

Follow these naming patterns when creating new branches:

- `feature/short-description`: For new features (e.g., `feature/add-gnss-parser`)
- `bugfix/issue-number`: For bug fixes (e.g., `bugfix/42-fix-parsing-error`)
- `hotfix/short-description`: For critical fixes to production code
- `release/vX.Y.Z`: For release preparation (e.g., `release/v1.2.0`)
- `docs/description`: For documentation updates (e.g., `docs/update-README`)

## Branch Workflow

1. **Feature Development**:
   - Create branch from: `develop`
   - Merge back into: `develop`
   - Naming: `feature/short-description`

2. **Bug Fixes**:
   - Create branch from: `develop`
   - Merge back into: `develop`
   - Naming: `bugfix/issue-number`

3. **Hotfixes**:
   - Create branch from: `main`
   - Merge back into: `main` AND `develop`
   - Naming: `hotfix/short-description`
   - Increment patch version

4. **Release Process**:
   - Create branch from: `develop`
   - Merge back into: `main` AND `develop`
   - Naming: `release/vX.Y.Z`
   - Tag the merge commit on `main` with version number

## Merging Strategy

- Always use pull requests for merging into protected branches
- Squash and merge for feature branches to keep history clean
- No fast-forward merges for release branches to maintain historical context
- Delete feature/bugfix branches after successful merge

## Version Control Practices

- Commit early and often in feature branches
- Write meaningful commit messages following conventional commits
- Keep pull requests focused on a single issue or feature
- Rebase feature branches on `develop` before requesting review

## Release Flow

1. Create a `release/vX.Y.Z` branch from `develop`
2. Make any final adjustments and version bumps
3. Create a pull request to merge into `main`
4. After approval and merge, tag the merge commit on `main` with the version
5. Create a pull request to merge changes back to `develop`
6. Delete the release branch after both merges are complete

# PYTHON_GUIDELINES

## Code Style & Standards

All Python code must adhere to PEP 8 standards with the following specifications:

- Line length: maximum 88 characters (Black default)
- Indentation: 4 spaces, no tabs
- Naming conventions:
  - `snake_case` for variables, functions, methods, modules
  - `PascalCase` for classes
  - `UPPER_CASE` for constants
  - Private attributes/methods prefixed with underscore (`_private_method`)
- String quotes: prefer double quotes (`"`) for strings
- Docstrings: Google style format for all modules, classes, and functions

## Type Hinting

Type hints are mandatory for all new code:

```python
def parse_gnss_data(raw_data: str) -> Dict[str, float]:
    """Parse raw GNSS data string into structured data.
    
    Args:
        raw_data: Raw GNSS data string from receiver
        
    Returns:
        Dictionary with parsed GNSS metrics
    """
    # Implementation...
```

- Use `Optional[Type]` for parameters that might be None
- Use `Union[Type1, Type2]` for parameters accepting multiple types
- Use `List`, `Dict`, `Tuple`, etc. from `typing` module (Python <3.9) or built-in annotation syntax (Python ≥3.9)
- Add return type annotations for all functions (use `-> None` for void functions)
- Use `typing.TypedDict` for dictionaries with specific schema

## Testing

All code must have corresponding tests using pytest:

- Test files should be placed in the `tests/` directory mirroring the package structure
- Test functions should begin with `test_`
- Test classes should begin with `Test`
- Use fixtures for common setup/teardown logic
- Aim for at least 80% code coverage
- Include unit tests for individual functions/classes
- Include integration tests for API interfaces

Example test structure:
```python
import pytest
from ap_gnss_stats.parser import parse_gnss_data

def test_parse_gnss_data_valid_input():
    sample_data = "$GPGGA,123519,4807.038,N,01131.000,E,1,08,0.9,545.4,M,46.9,M,,*47"
    result = parse_gnss_data(sample_data)
    assert "latitude" in result
    assert result["latitude"] == pytest.approx(48.1173)
```

## Dependency Management

- All dependencies must be specified in both `setup.py` and `requirements.txt`
- Development dependencies should be in `requirements-dev.txt`
- Use semantic versioning constraints (e.g., `>=1.2.0, <2.0.0`)
- Pin exact versions in CI/CD pipelines for reproducibility
- Use virtual environments for development:
  ```bash
  python -m venv venv
  source venv/bin/activate  # On Windows: venv\Scripts\activate
  pip install -e .
  ```

## Documentation

- All modules, classes, and functions must have docstrings
- Use Google style docstrings format
- Include examples in docstrings for public API functions
- Keep README.md updated with installation and basic usage
- Generate API documentation using Sphinx

## Error Handling

- Be specific with exceptions, avoid bare `except:` clauses
- Custom exceptions should inherit from appropriate base exceptions
- Log exceptions with appropriate severity levels
- Return meaningful error messages and status codes from public APIs

## Performance Considerations

- Prefer list/dict comprehensions over loops for simple transformations
- Use generators for handling large datasets
- Profile code for performance bottlenecks when processing large GNSS datasets
- Consider async processing for I/O-bound operations

## Linting & Code Quality Tools

The project uses the following tools:

- `black`: Code formatting
- `isort`: Import sorting
- `flake8`: Code linting
- `mypy`: Static type checking
- `pylint`: Advanced code analysis
- `bandit`: Security linting

Configuration files for these tools should be in the repository root.

# PROJECT_STRUCTURE

## Directory Layout

The ap-gnss-stats project should follow this standard directory structure:

```
ap-gnss-stats/
├── .github/                    # GitHub specific files
│   ├── workflows/              # GitHub Actions workflow files
│   ├── ISSUE_TEMPLATE/         # Issue templates
│   └── PULL_REQUEST_TEMPLATE.md # PR template
├── ap_gnss_stats/              # Main package directory
│   ├── __init__.py             # Package initialization
│   ├── cli.py                  # Command line interface
│   ├── config.py               # Configuration handling
│   ├── exceptions.py           # Custom exceptions
│   ├── parser/                 # Log parsing functionality
│   │   ├── __init__.py
│   │   ├── putty_logs.py       # PuTTY log parser
│   │   ├── cisco_gnss.py       # Cisco GNSS output parser
│   │   └── patterns.py         # Regex patterns for extraction
│   ├── connection/             # Connection handling
│   │   ├── __init__.py
│   │   ├── ssh.py              # SSH connection to AP
│   │   └── batch.py            # Batch processing of multiple APs
│   ├── models/                 # Data models
│   │   ├── __init__.py
│   │   ├── ap_data.py          # AP data models
│   │   └── gnss_data.py        # GNSS data models
│   ├── analysis/               # Statistical analysis functions
│   │   ├── __init__.py
│   │   ├── accuracy.py         # Position accuracy metrics
│   │   ├── comparison.py       # Compare data between APs
│   │   └── stability.py        # Signal stability over time
│   └── utils/                  # Utility functions
│       ├── __init__.py
│       ├── logging.py          # Logging configuration
│       └── geo.py              # Geographic calculations
├── tests/                      # All tests
│   ├── __init__.py
│   ├── conftest.py             # pytest fixtures
│   ├── test_cli.py
│   ├── parser/
│   │   ├── test_putty_logs.py
│   │   └── test_cisco_gnss.py
│   ├── connection/
│   │   ├── test_ssh.py
│   │   └── test_batch.py
│   └── analysis/
│       ├── test_accuracy.py
│       └── test_comparison.py
├── docs/                       # Documentation
│   ├── conf.py                 # Sphinx configuration
│   ├── index.rst               # Documentation index
│   ├── installation.rst        # Installation guide
│   ├── api/                    # API reference
│   └── examples/               # Example usage
├── sample_data/                # Sample log files for testing
│   ├── good_fix/               # Logs with good GPS fix
│   ├── no_fix/                 # Logs with no GPS fix
│   └── mixed/                  # Mixed quality logs
├── examples/                   # Example scripts
│   ├── basic_usage.py
│   ├── batch_collection.py
│   └── time_series_analysis.py
├── .gitignore                  # Git ignore file
├── LICENSE                     # License file
├── README.md                   # Project readme
├── CHANGELOG.md                # Version changelog
├── setup.py                    # Package setup file
├── setup.cfg                   # Package configuration
├── pyproject.toml              # Project configuration (for Black, etc.)
├── requirements.txt            # Production dependencies
└── requirements-dev.txt        # Development dependencies
```

## Module Responsibilities

### Core Modules

- **parser/**: Contains parsers for Cisco AP GNSS data
  - `putty_logs.py`: Parse PuTTY log files containing `show gnss info` output
  - `cisco_gnss.py`: Parse and extract structured data from Cisco GNSS output
  - `patterns.py`: Regular expression patterns for data extraction

- **connection/**: Manages connections to Cisco Access Points
  - `ssh.py`: SSH connection handling and command execution
  - `batch.py`: Batch processing of multiple APs

- **models/**: Data structure definitions
  - `ap_data.py`: Models for AP metadata (hostname, location, etc.)
  - `gnss_data.py`: Models for GNSS data (coordinates, accuracy, satellites)

- **analysis/**: Statistical analysis of GNSS data
  - `accuracy.py`: Position accuracy metrics calculations
  - `comparison.py`: Compare GNSS data between different APs
  - `stability.py`: Track signal stability and quality over time

### Support Modules

- **utils/**: General utility functions
  - `logging.py`: Logging configuration
  - `geo.py`: Geographic calculations (distance between points, etc.)

- **cli.py**: Command-line interface
- **config.py**: Configuration management
- **exceptions.py**: Custom exceptions

## File Organization Rules

1. **New Features**:
   - Place feature code in the appropriate module
   - If a feature crosses multiple domains, discuss with team for placement
   - Create new modules for distinct functionality domains

2. **Tests**:
   - Mirror the package structure in the tests directory
   - One test file per module being tested
   - Use sample data from sample_data/ directory for tests

3. **Documentation**:
   - API documentation should be generated from docstrings
   - Examples should demonstrate complete workflows
   - Tutorials should be in the docs directory

4. **Data Files**:
   - Sample log files should be in the sample_data/ directory
   - Organized by quality of fix (good_fix/, no_fix/, mixed/)

## Data Models

Key data models should include:

1. **APData**:
   - Hostname (e.g., "su-104a-ap1")
   - Location (building, floor, etc.)
   - AP model
   - Firmware version

2. **GNSSData**:
   - FixStatus (3D-Fix, No-Fix)
   - ValidFix (boolean)
   - Timestamp
   - Coordinates (lat/long)
   - Accuracy metrics (HorAcc, hDOP)
   - Uncertainty ellipse data
   - Altitude information (MSL, HAE)
   - Satellite counts
   - Source (direct GNSS, PostProcessor, CiscoGNSS)

3. **SatelliteData**:
   - Constellation (GPS, Galileo)
   - Satellite ID
   - Signal strength (CNO)
   - Elevation/Azimuth
   - Used status

## Import Conventions

- Use absolute imports within the package
- All public functions/classes should be imported in `__init__.py` 
- Avoid circular imports by properly organizing the dependency graph

## Entry Points

The package should define these entry points:
- CLI tool named `ap-gnss` for command-line operations
- Main API through the package's `__init__.py`

# DEPENDENCY_MANAGEMENT

## Package Dependencies

The ap-gnss-stats project should manage dependencies according to these guidelines:

### Primary Dependencies

Core dependencies should be kept minimal and focused:

- **netmiko**: Network equipment SSH connection library for Cisco APs
- **pandas**: Data manipulation and analysis
- **numpy**: Numerical operations
- **matplotlib/plotly**: Visualization of GNSS data
- **click**: Command-line interface creation
- **pyyaml**: Configuration file parsing
- **python-dateutil**: Date/time handling
- **dataclasses-json**: JSON serialization/deserialization for data models

### Version Specification

For `requirements.txt`:
```
# Core dependencies
netmiko==4.3.0
pandas==2.1.0
numpy==1.24.3
matplotlib==3.7.2
plotly==5.18.0
click==8.1.7
pyyaml==6.0.1
python-dateutil==2.8.2
dataclasses-json==0.6.1

# Optional dependencies
jupyter==1.0.0
```

For `setup.py`:
```python
install_requires=[
    "netmiko>=4.2.0,<5.0.0",
    "pandas>=2.0.0,<3.0.0",
    "numpy>=1.24.0,<2.0.0",
    "matplotlib>=3.7.0,<4.0.0",
    "plotly>=5.15.0,<6.0.0",
    "click>=8.1.0,<9.0.0",
    "pyyaml>=6.0.0,<7.0.0",
    "python-dateutil>=2.8.0,<3.0.0",
    "dataclasses-json>=0.5.0,<1.0.0",
],
extras_require={
    "dev": [
        "pytest>=7.0.0,<8.0.0",
        "pytest-cov>=4.1.0,<5.0.0",
        "black>=23.0.0,<24.0.0",
        "isort>=5.12.0,<6.0.0",
        "mypy>=1.4.0,<2.0.0",
        "flake8>=6.0.0,<7.0.0",
        "sphinx>=7.0.0,<8.0.0",
    ],
    "interactive": [
        "jupyter>=1.0.0,<2.0.0",
        "ipywidgets>=8.0.0,<9.0.0",
    ],
}
```

## Development Environment

### Virtual Environment

All development should occur within a virtual environment:

```bash
# Creating a virtual environment
python -m venv venv

# Activating the virtual environment
# On Windows:
venv\Scripts\activate
# On Unix/macOS:
source venv/bin/activate

# Installing dependencies for development
pip install -e ".[dev]"
```

### Lock Files

For reproducible environments, generate lock files:

```bash
# Generate a requirements.txt from the current environment
pip freeze > requirements-lock.txt
```

### CI/CD Environment

CI pipelines should use the exact versions from the lock file:

```yaml
- name: Install dependencies
  run: |
    python -m pip install --upgrade pip
    pip install -r requirements-lock.txt
```

## Dependency Scanning

### Security Scanning

Regularly scan dependencies for security issues:

```bash
# Using safety
pip install safety
safety check -r requirements.txt

# Using pip-audit
pip install pip-audit
pip-audit
```

### Dependency Updates

Guidelines for updating dependencies:

1. **Regular Reviews**: Schedule monthly reviews of all dependencies
2. **Automated Updates**: Use Dependabot for GitHub to automatically open PRs for updates
3. **Update Process**:
   - Update minor/patch versions without extensive review
   - Major version updates require thorough testing and approval
   - Document all significant dependency changes in CHANGELOG.md

## Configuration for Dependency Tools

### pip config

```ini
[global]
timeout = 60
```

### .pypirc (for package publishing)

```ini
[distutils]
index-servers =
    pypi
    testpypi

[pypi]
username = __token__
password = <PyPI API token>

[testpypi]
repository = https://test.pypi.org/legacy/
username = __token__
password = <TestPyPI API token>
```

## Optional Dependencies

Handle optional dependencies explicitly:

```python
try:
    import jupyter
    HAS_JUPYTER = True
except ImportError:
    HAS_JUPYTER = False

def generate_interactive_report():
    if not HAS_JUPYTER:
        raise ImportError("Interactive reports require jupyter. "
                         "Install with `pip install ap-gnss-stats[interactive]`")
    # Implementation...
```

## Netmiko Connection Example

Basic usage example for connecting to Cisco APs:

```python
from netmiko import ConnectHandler

def get_gnss_info(hostname, username, password):
    """
    Connect to a Cisco AP and retrieve GNSS information.
    
    Args:
        hostname: AP hostname or IP address
        username: SSH username
        password: SSH password
        
    Returns:
        str: Raw output of 'show gnss info' command
    """
    device = {
        'device_type': 'cisco_ios',  # Use appropriate device type for your AP model
        'host': hostname,
        'username': username,
        'password': password,
    }
    
    try:
        with ConnectHandler(**device) as conn:
            output = conn.send_command('show gnss info')
            return output
    except Exception as e:
        raise ConnectionError(f"Failed to connect to {hostname}: {str(e)}")
```

## Containerization

Include a Dockerfile for containerized usage:

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
RUN pip install -e .

ENTRYPOINT ["ap-gnss"]
CMD ["--help"]
```

# ERROR_HANDLING_STANDARDS

## Exception Hierarchy

The ap-gnss-stats project should implement a custom exception hierarchy:

```python
# In ap_gnss_stats/exceptions.py

class APGNSSError(Exception):
    """Base exception for all ap-gnss-stats errors."""
    pass

class ConnectionError(APGNSSError):
    """Raised when connection to AP fails."""
    pass

class CommandError(APGNSSError):
    """Raised when a command fails to execute properly."""
    pass

class ParseError(APGNSSError):
    """Raised when parsing of GNSS data fails."""
    pass

class ValidationError(APGNSSError):
    """Raised when data validation fails."""
    pass

class ConfigurationError(APGNSSError):
    """Raised when there's an issue with configuration."""
    pass

class AnalysisError(APGNSSError):
    """Raised when analysis of GNSS data fails."""
    pass
```

## Exception Handling Guidelines

### General Principles

1. **Be Specific**: Catch specific exceptions, not broad exception types
2. **Contextual Information**: Include context in error messages
3. **Graceful Degradation**: Allow partial functionality when possible
4. **Log All Exceptions**: Ensure exceptions are properly logged
5. **Clean Up Resources**: Use context managers and `finally` blocks

### Examples of Good Exception Handling

```python
# Good - Specific exception handling with context
try:
    connection = establish_ap_connection(hostname, username, password)
    results = connection.execute_command("show gnss info")
except netmiko.exceptions.NetmikoTimeoutException:
    logger.error(f"Connection timeout to AP {hostname}")
    raise ConnectionError(f"Timed out connecting to AP {hostname}")
except netmiko.exceptions.NetmikoAuthenticationException:
    logger.error(f"Authentication failed for AP {hostname}")
    raise ConnectionError(f"Authentication failed for AP {hostname}")
except Exception as e:
    logger.error(f"Unexpected error connecting to AP {hostname}: {str(e)}")
    raise ConnectionError(f"Failed to connect to AP {hostname}: {str(e)}")
finally:
    if 'connection' in locals() and connection:
        connection.disconnect()
```

### Examples to Avoid

```python
# Bad - Too broad exception handling
try:
    # Complex operations
    parse_all_ap_logs(directory)
except Exception:  # Too broad!
    print("Error occurred")  # No context, poor handling

# Bad - Suppressing exceptions without logging
try:
    result = process_gnss_data(data)
except:  # Bare except clause - avoid this!
    result = None  # Silently failing
```

## Logging Practices

### Log Levels

- **ERROR**: Record exceptions and application errors
- **WARNING**: Record potentially problematic situations
- **INFO**: Record general operational information
- **DEBUG**: Record detailed debug information

### Error Logging Format

All error logs should include:

1. Timestamp
2. Error level
3. Module/function where error occurred
4. Clear error message
5. Exception type and traceback (when applicable)

```python
# In ap_gnss_stats/utils/logging.py

import logging
import traceback
from datetime import datetime

def setup_logger(name, log_file=None, level=logging.INFO):
    """Set up and return a logger with the specified configuration."""
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    if log_file:
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    return logger

def log_exception(logger, message, exception=None):
    """Log an exception with traceback."""
    if exception:
        logger.error(
            f"{message}: {type(exception).__name__}: {str(exception)}\n"
            f"Traceback: {traceback.format_exc()}"
        )
    else:
        logger.error(message)
```

## User-Facing Error Messages

### CLI Error Display

Command-line interface errors should:

1. Be concise and clear
2. Provide context about what was happening
3. Suggest potential solutions
4. Include a specific error code when applicable

```python
# In ap_gnss_stats/cli.py

import click
import sys
from .exceptions import APGNSSError

def handle_cli_error(func):
    """Decorator to handle CLI errors."""
    @click.pass_context
    def wrapper(ctx, *args, **kwargs):
        try:
            return func(ctx, *args, **kwargs)
        except ConnectionError as e:
            click.echo(f"Error: Could not connect to AP. {str(e)}", err=True)
            click.echo("Please verify hostname, credentials, and network connectivity.", err=True)
            sys.exit(1)
        except CommandError as e:
            click.echo(f"Error: Command execution failed. {str(e)}", err=True)
            sys.exit(2)
        except ParseError as e:
            click.echo(f"Error: Failed to parse GNSS data. {str(e)}", err=True)
            click.echo("The output format may have changed or data is corrupted.", err=True)
            sys.exit(3)
        except ConfigurationError as e:
            click.echo(f"Error: Invalid configuration. {str(e)}", err=True)
            click.echo("Please check your configuration file syntax.", err=True)
            sys.exit(4)
        except APGNSSError as e:
            click.echo(f"Error: {str(e)}", err=True)
            sys.exit(10)
        except Exception as e:
            click.echo(f"Unexpected error: {str(e)}", err=True)
            click.echo("This is likely a bug, please report it with the error details.", err=True)
            sys.exit(99)
    return wrapper
```

## Error Recovery Strategies

### Retry Mechanism

For transient errors like connection issues, implement retry with exponential backoff:

```python
import time
from functools import wraps

def retry(max_attempts=3, backoff_factor=2, exceptions=(ConnectionError,)):
    """Retry decorator with exponential backoff."""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            attempt = 0
            while attempt < max_attempts:
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    attempt += 1
                    if attempt >= max_attempts:
                        raise
                    wait_time = backoff_factor ** attempt
                    logger.warning(
                        f"Attempt {attempt} failed with {type(e).__name__}: {str(e)}. "
                        f"Retrying in {wait_time} seconds..."
                    )
                    time.sleep(wait_time)
        return wrapper
    return decorator
```

### Partial Results

When processing multiple APs or data points, return partial results when possible:

```python
def process_multiple_aps(ap_list):
    """Process multiple APs and return results, even if some fail."""
    results = {}
    errors = {}
    
    for ap in ap_list:
        try:
            results[ap] = process_single_ap(ap)
        except APGNSSError as e:
            errors[ap] = str(e)
            logger.error(f"Error processing AP {ap}: {str(e)}")
    
    return {
        'successful': results,
        'failed': errors,
        'success_rate': len(results) / (len(results) + len(errors)) if ap_list else 0
    }
```

## Data Validation

Implement validation for all user inputs and parsed data:

```python
def validate_gnss_data(gnss_data):
    """
    Validate GNSS data structure and values.
    
    Args:
        gnss_data: Parsed GNSS data dictionary
        
    Returns:
        bool: True if valid
        
    Raises:
        ValidationError: If validation fails
    """
    required_fields = ['Latitude', 'Longitude', 'HorAcc', 'Fix']
    
    # Check required fields exist
    for field in required_fields:
        if field not in gnss_data:
            raise ValidationError(f"Missing required field: {field}")
    
    # Validate latitude range
    if not (-90 <= gnss_data['Latitude'] <= 90):
        raise ValidationError(f"Invalid latitude value: {gnss_data['Latitude']}")
    
    # Validate longitude range
    if not (-180 <= gnss_data['Longitude'] <= 180):
        raise ValidationError(f"Invalid longitude value: {gnss_data['Longitude']}")
    
    # Validate known fix types
    if gnss_data['Fix'] not in ['No-Fix', '2D-Fix', '3D-Fix']:
        raise ValidationError(f"Unknown fix type: {gnss_data['Fix']}")
    
    return True
```

## Debugging Assistance

Include debug helpers to assist in troubleshooting:

```python
def dump_debug_info(ap_hostname, output, error=None):
    """
    Dump debug information to a file for troubleshooting.
    
    Args:
        ap_hostname: Hostname of the AP
        output: Command output or data being processed
        error: Exception object if available
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"debug_{ap_hostname}_{timestamp}.log"
    
    with open(filename, 'w') as f:
        f.write(f"==== Debug information for {ap_hostname} at {timestamp} ====\n\n")
        f.write("=== Command Output ===\n")
        f.write(output)
        f.write("\n\n=== Error Details ===\n")
        if error:
            f.write(f"Error type: {type(error).__name__}\n")
            f.write(f"Error message: {str(error)}\n")
            f.write(f"Traceback:\n{traceback.format_exc()}\n")
        else:
            f.write("No error object provided\n")
    
    return filename
```
# SECURITY_GUIDELINES

## Credential Management

### SSH Authentication

When connecting to Cisco APs, follow these security practices:

1. **Never hardcode credentials** in source code
2. **Use dotenv and environment variables** for credential management:

```python
import os
from dotenv import load_dotenv
from getpass import getpass

# Load environment variables from .env file
load_dotenv()

# Getting credentials securely
def get_credentials():
    """Get credentials from environment or prompt securely."""
    username = os.environ.get("AP_USERNAME")
    password = os.environ.get("AP_PASSWORD")
    
    if not username:
        username = input("Enter username: ")
    
    if not password:
        password = getpass("Enter password: ")
    
    return username, password
```

Example `.env` file (should be added to .gitignore):

```
# AP Access Credentials
AP_USERNAME=admin
AP_PASSWORD=secure_password

# Connection Settings
AP_SSH_PORT=22
AP_CONNECTION_TIMEOUT=30

# Default AP List
DEFAULT_AP_LIST=ap1.example.com,ap2.example.com,ap3.example.com

# Logging
LOG_LEVEL=INFO
LOG_FILE=/path/to/logs/ap-gnss.log
```

3. **Support SSH key authentication** when available:

```python
from netmiko import ConnectHandler

def connect_with_key(hostname, username, key_file):
    """Connect to an AP using SSH key authentication."""
    device = {
        'device_type': 'cisco_ios',
        'host': hostname,
        'username': username,
        'use_keys': True,
        'key_file': key_file,
    }
    
    return ConnectHandler(**device)
```

### Credential Storage

1. **Configuration files with credentials** must:
   - Be excluded from version control (add to .gitignore)
   - Have restricted file permissions (0600)

```python
import os
import stat

def secure_dotenv_permissions():
    """Set secure permissions on .env file."""
    if os.path.exists('.env'):
        # Set file permissions to owner read/write only (0600)
        os.chmod('.env', stat.S_IRUSR | stat.S_IWUSR)
```

Add to `.gitignore`:

```
# Ignore .env file containing credentials
.env
.env.*

# Ignore log files
*.log
logs/

# Ignore collected data files
data/
```

## Network Security

### SSH Connection Security

1. **Enforce SSH version 2** for all connections
2. **Implement connection timeouts** to prevent hanging sessions
3. **Close connections promptly** after use:

```python
def execute_command_safely(device_params, command):
    """Execute a command with proper connection handling."""
    try:
        with ConnectHandler(**device_params) as conn:
            result = conn.send_command(command)
            return result
    finally:
        # ConnectHandler context manager ensures disconnect
        pass
```

### Network Access Control

1. **Use SSH, not Telnet** for AP connections
2. **Implement reasonable timeouts** to prevent resource exhaustion

## Data Collection Security

### GNSS Data Collection

1. **Store data without encryption**:
   - As specified, GNSS data should be stored in plain text for easy analysis
   - Focus on access control via file system permissions instead

2. **AP Information Collection**:
   - Collect only necessary information from APs
   - Document what data is being collected for transparency

```python
def collect_ap_data(conn):
    """
    Collect AP data including GNSS information.
    Data will be stored in plain text as per requirements.
    """
    commands = [
        "show gnss info",
        "show version | include Version",
        "show inventory"
    ]
    
    results = {}
    for cmd in commands:
        results[cmd] = conn.send_command(cmd)
    
    return results
```

### Log Security

1. **Log file security**:
   - Restrict permissions (0600)
   - Implement log rotation
   - Do not log credentials

```python
def setup_secure_logger(name, log_file=None):
    """Set up a logger with secure file handling."""
    logger = logging.getLogger(name)
    
    if log_file:
        handler = logging.FileHandler(log_file)
        handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        logger.addHandler(handler)
        
        # Secure log file permissions
        os.chmod(log_file, stat.S_IRUSR | stat.S_IWUSR)
    
    return logger
```

## Code Security

### Input Validation

1. **Validate all inputs** from untrusted sources:
   - Command-line arguments
   - Configuration files
   - Data from network sources

```python
def validate_hostname(hostname):
    """Validate hostname for security."""
    import re
    if not hostname or not re.match(r'^[a-zA-Z0-9_\-\.]+$', hostname):
        raise ValueError("Invalid hostname format")
    return hostname
```

2. **Command injection prevention**:

```python
def safe_command_execution(conn, command, allowed_commands=None):
    """Execute command safely, preventing command injection."""
    # Validate command is in whitelist
    if allowed_commands and command not in allowed_commands:
        raise SecurityError(f"Command not allowed: {command}")
    
    # Ensure no command chaining
    if any(c in command for c in [';', '&&', '||', '|', '>']):
        raise SecurityError(f"Invalid command format: {command}")
    
    return conn.send_command(command)
```

### Dependency Security

1. **Regular security scanning** of dependencies
2. **Pinned dependency versions** to prevent supply chain attacks

```bash
# Set in requirements.txt or similar
pip install --require-hashes -r requirements-lock.txt
```

## Secure Deployment

### Principle of Least Privilege

1. **Run services with minimal privileges** required
2. **Use read-only access** when write operations are not needed
3. **Consider creating dedicated** read-only accounts for AP data collection

```python
# Example device params using read-only account
device_params = {
    'device_type': 'cisco_ios',
    'host': hostname,
    'username': os.environ.get('AP_RO_USERNAME', 'readonly'),
    'password': os.environ.get('AP_RO_PASSWORD'),
    'port': int(os.environ.get('AP_SSH_PORT', 22)),
    'timeout': int(os.environ.get('AP_CONNECTION_TIMEOUT', 30)),
}
```

### Secrets Management

1. **Environment-specific variables** for different deployments:
   - Development
   - Testing
   - Production

2. **CI/CD security**:
   - Use GitHub Secrets or similar for CI/CD pipelines
   - Avoid printing sensitive values in build logs

```yaml
# Example GitHub Actions secret usage
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run tests
        env:
          TEST_AP_USERNAME: ${{ secrets.TEST_AP_USERNAME }}
          TEST_AP_PASSWORD: ${{ secrets.TEST_AP_PASSWORD }}
        run: pytest tests/
```

## Security Documentation

### Security Practices Documentation

1. **Document security protocols** for users and contributors
2. **Include secure usage examples** in documentation
3. **Provide a security policy** (SECURITY.md) with:
   - Supported versions
   - Reporting process for vulnerabilities
   - Expected response timeframe

### Security Contacts

Current security contacts (Updated: 2025-04-28 20:11:48):
- Luke Jenkins (@lukejenkins) - Primary security contact

Report security issues privately to the above security contacts or via GitHub Security Advisories.

# CONTRIBUTION_GUIDELINES

## Development Process

### Getting Started

1. **Fork and clone** the repository:
   ```bash
   git clone https://github.com/yourusername/ap-gnss-stats.git
   cd ap-gnss-stats
   ```

2. **Set up the development environment**:
   ```bash
   # Create and activate virtual environment
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   
   # Install development dependencies
   pip install -e ".[dev]"
   ```

3. **Create a .env file** for local configuration:
   ```bash
   cp .env.example .env
   # Edit .env with your settings
   ```

### Branch Naming

Follow the branch naming convention:
- `feature/short-description` - For new features
- `bugfix/issue-number` - For bug fixes
- `docs/topic` - For documentation improvements
- `refactor/component` - For code refactoring

Example:
```bash
git checkout -b feature/batch-processing
```

## Code Standards

### Style Guide

This project follows PEP 8 with the following tools:
- **Black** for code formatting
- **isort** for import sorting
- **flake8** for linting
- **mypy** for type checking

Run these tools before committing:
```bash
# Format code
black ap_gnss_stats/ tests/

# Sort imports
isort ap_gnss_stats/ tests/

# Lint code
flake8 ap_gnss_stats/ tests/

# Type check
mypy ap_gnss_stats/
```

### Documentation

- All modules, classes, and functions must have docstrings
- Use Google-style docstrings:

```python
def parse_gnss_info(output: str) -> Dict[str, Any]:
    """
    Parse GNSS information from AP command output.
    
    Args:
        output: Raw output from 'show gnss info' command
        
    Returns:
        Dictionary containing parsed GNSS data
        
    Raises:
        ParseError: If the output cannot be parsed correctly
        
    Example:
        >>> output = '''GnssState: Started
        ... Fix: 3D-Fix ValidFix: true
        ... Latitude: 41.12345 Longitude: -111.98765
        ... '''
        >>> parse_gnss_info(output)
        {'GnssState': 'Started', 'Fix': '3D-Fix', ...}
    """
```

## Testing

### Writing Tests

- Write tests using pytest
- Maintain at least 80% code coverage
- Create test fixtures for reusable test components:

```python
@pytest.fixture
def sample_gnss_output():
    """Return a sample GNSS output for testing."""
    with open('tests/data/sample_gnss_info.txt', 'r') as f:
        return f.read()

def test_parse_gnss_info(sample_gnss_output):
    """Test that GNSS info is parsed correctly."""
    result = parse_gnss_info(sample_gnss_output)
    assert result['Fix'] == '3D-Fix'
    assert result['Latitude'] == pytest.approx(41.12345)
```

### Running Tests

Run tests before submitting a pull request:
```bash
# Run all tests
pytest

# Run with coverage report
pytest --cov=ap_gnss_stats --cov-report=term-missing
```

## Submission Process

### Commit Guidelines

- Use conventional commit messages:
  ```
  feat: add batch processing for multiple APs
  fix: correct latitude parsing error
  docs: update installation instructions
  test: add tests for GNSS parsing
  refactor: simplify connection handling
  ```

- Keep commits focused on a single change
- Include issue numbers when relevant:
  ```
  fix: correct timeout errors (#42)
  ```

### Pull Request Process

1. **Create a pull request** from your feature branch to the main repository's develop branch
2. **Fill out the pull request template** completely
3. **Ensure CI checks pass**
4. **Request a review** from at least one maintainer
5. **Address review comments** promptly
6. **Update documentation** if necessary

### Pull Request Review Criteria

Pull requests must meet these criteria:
- Tests pass
- Code coverage is maintained or improved
- Documentation is updated
- Code follows style guidelines
- Functionality is tested on relevant environments

## Issue Reporting

### Bug Reports

When reporting a bug, include:
1. Description of the problem
2. Steps to reproduce
3. Expected vs. actual behavior
4. Environment details (OS, Python version, package version)
5. Logs or error messages
6. Potential solution if you have one

### Feature Requests

When requesting a feature, include:
1. Clear description of the requested feature
2. Rationale: why is this feature valuable?
3. Acceptance criteria: how will we know it's done?
4. Any relevant examples, mock-ups, or use cases

## Release Process

### Version Numbering

Follow semantic versioning (MAJOR.MINOR.PATCH):
- MAJOR: incompatible API changes
- MINOR: backward-compatible new functionality
- PATCH: backward-compatible bug fixes

### Release Checklist

Before releasing:
- Ensure all tests pass
- Update CHANGELOG.md
- Update version number in setup.py and __init__.py
- Create and merge a release PR
- Tag the release with git
- Build and publish to PyPI

## Community Guidelines

### Code of Conduct

All contributors must follow our Code of Conduct:
- Be respectful and inclusive
- Focus on constructive feedback
- Maintain a harassment-free community
- Report unacceptable behavior to maintainers

### Communication Channels

- GitHub Issues: Bug reports and feature requests
- Pull Requests: Code reviews and discussions
- Project Wiki: Documentation and guides
- Community Chat: Real-time collaboration

## Current Maintainers

Current maintainers (Updated: 2025-04-28 20:13:48):
- Luke Jenkins (@lukejenkins) - Primary maintainer
